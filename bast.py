import json
import os
from datetime import datetime
from typing import List, Dict, Any, Tuple
import os
import multiprocessing
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# è®¾ç½®SWIFTç¯å¢ƒå˜é‡æ¥æŠ‘åˆ¶WARNINGæ—¥å¿—
if 'CUDA_VISIBLE_DEVICES' not in os.environ:
    os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'
os.environ['LOG_LEVEL'] = 'ERROR'  # æŠ‘åˆ¶SWIFTçš„WARNINGä¿¡æ¯
import matplotlib.font_manager as fm
import matplotlib.pyplot as plt
import tqdm
from matplotlib import rcParams
from PIL import Image
from swift.llm import InferRequest, VllmEngine, RequestConfig

# --- å¸¸é‡é…ç½® ---
MODEL_PATH = ''
VQA_DATA_PATH = 'data/VQA-SA-question.json'
OUTPUT_DIR = os.path.join(os.path.dirname(__file__), 'InternVL3-output')
RESULTS_JSON_PATH = os.path.join(os.path.dirname(__file__), 'VQA-SA-results.json')
FONT_PATH = os.path.join(os.path.dirname(__file__), 'src/NotoSansSC-Regular.otf')
SUBMIT_TO_EVALAI = True  # å…¨å±€å¼€å…³ï¼šè®¾ç½®ä¸º True ä»¥å¯ç”¨æäº¤åŠŸèƒ½

# --- å¯è§†åŒ–å¤šçº¿ç¨‹é…ç½® ---
ENABLE_MULTITHREADED_VISUALIZATION = True  # å¯ç”¨å¤šçº¿ç¨‹å¯è§†åŒ–åŠ é€Ÿ
MAX_VISUALIZATION_WORKERS = None  # æœ€å¤§çº¿ç¨‹æ•°ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨CPUæ ¸å¿ƒæ•°

# --- ä¸»é€»è¾‘ ---

def main():
    """
    è§†è§‰é—®ç­”æ‰¹é‡æ¨ç†ä¸»ç¨‹åºã€‚
    """
    # 1. åˆå§‹åŒ–ç¯å¢ƒ
    setup_matplotlib_font()
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    print(f"è¾“å‡ºç›®å½•å·²åˆ›å»º/ç¡®è®¤å­˜åœ¨: {OUTPUT_DIR}")

    # 2. åŠ è½½æ•°æ®
    vqa_data = load_vqa_data(VQA_DATA_PATH)
    if not vqa_data:
        print("æœªèƒ½åŠ è½½VQAæ•°æ®ï¼Œç¨‹åºç»ˆæ­¢ã€‚")
        return
    # å•è¿›ç¨‹æ¨¡å¼: ä½¿ç”¨æ‰€æœ‰é…ç½®çš„GPU
    # 3. åˆå§‹åŒ–æ¨ç†å¼•æ“
    engine = initialize_inference_engine(MODEL_PATH)
    request_config = create_request_config()

    # 4. å‡†å¤‡æ¨ç†è¯·æ±‚
    print("å¼€å§‹å‡†å¤‡æ¨ç†è¯·æ±‚...")
    requests, items = prepare_inference_requests(vqa_data)
    if not requests:
        print("æ²¡æœ‰å¯å¤„ç†çš„æœ‰æ•ˆæ¨ç†è¯·æ±‚ï¼Œç¨‹åºç»ˆæ­¢ã€‚")
        return

    # 5. æ‰§è¡Œæ‰¹é‡æ¨ç†
    print("å¼€å§‹æ‰§è¡Œæ‰¹é‡æ¨ç†...")
    responses = engine.infer(requests, request_config,use_tqdm=True)
    print("æ‰¹é‡æ¨ç†å®Œæˆã€‚")

    # 6. å¤„ç†æ¨ç†å“åº”
    print("å¼€å§‹å¤„ç†æ¨ç†å“åº”...")
    results = process_responses(responses, items)
    print("å“åº”å¤„ç†å®Œæˆã€‚")

    # 7. ç”Ÿæˆå¹¶ä¿å­˜å¯è§†åŒ–ç»“æœ
    print("å¼€å§‹ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
    if ENABLE_MULTITHREADED_VISUALIZATION:
        generate_visualizations(results, max_workers=MAX_VISUALIZATION_WORKERS)
    else:
        generate_visualizations_sequential(results)
    print("å¯è§†åŒ–ç»“æœç”Ÿæˆå®Œæˆã€‚")

    # 8. ä¿å­˜æœ€ç»ˆçš„èšåˆç»“æœ
    save_aggregated_results(results, RESULTS_JSON_PATH)

    print("\næ‰€æœ‰ä»»åŠ¡å·²å®Œæˆã€‚")
    print(f"èšåˆç»“æœå·²ä¿å­˜è‡³: {RESULTS_JSON_PATH}")
    print(f"å¯è§†åŒ–ç»“æœå›¾åƒå·²ä¿å­˜è‡³: {OUTPUT_DIR}")

    # 9. æäº¤åˆ° EvalAI
    if SUBMIT_TO_EVALAI:
        CHALLENGE_ID = "2552"
        PHASE_ID = "5069"  # ä¾‹å¦‚: "5557"
        SUBMISSION_TYPE = "--public"      # å¯é€‰é¡¹: "--public" æˆ– "--private"

        # å¯é€‰: é¢„è®¾æäº¤ç»†èŠ‚ï¼Œå¦‚æœä¸æƒ³å¡«å†™ï¼Œè¯·ä¿æŒå€¼ä¸ºç©ºå­—ç¬¦ä¸² ""
        SUBMISSION_DETAILS = {
            "method_name": "",
            "method_description": "",
            "project_url": "",
            "publication_url": ""
        }

        if PHASE_ID and PHASE_ID != "YOUR_PHASE_ID_HERE":
            submit_to_evalai(
                file_path=RESULTS_JSON_PATH,
                challenge_id=CHALLENGE_ID,
                phase_id=PHASE_ID,
                submission_type=SUBMISSION_TYPE,
                details=SUBMISSION_DETAILS
            )
        else:
            print("\n" + "="*50)
            print("æé†’: å·²è·³è¿‡å‘ EvalAI æäº¤ç»“æœçš„æ­¥éª¤ã€‚")
            print(f"åŸå› : `PHASE_ID` æœªè®¾ç½®æˆ–æ— æ•ˆã€‚è¯·åœ¨è„šæœ¬ `bast.py` ä¸­è®¾ç½®æœ‰æ•ˆçš„ `PHASE_ID`ã€‚")
            print("="*50)
    else:
        print("\n" + "="*50)
        print("æé†’: æ ¹æ®å…¨å±€è®¾ç½®ï¼Œå·²è·³è¿‡å‘ EvalAI æäº¤ç»“æœçš„æ­¥éª¤ã€‚")
        print(f"å¦‚éœ€è‡ªåŠ¨æäº¤ï¼Œè¯·åœ¨è„šæœ¬ `bast.py` ä¸­å°† `SUBMIT_TO_EVALAI` è®¾ç½®ä¸º `True`ã€‚")
        print("="*50)

def process_data_part(data_part, gpu_ids):
    """å¤„ç†æ•°æ®çš„ä¸€éƒ¨åˆ†ï¼Œä½¿ç”¨æŒ‡å®šçš„GPU"""
    
    try:
        print(f"ä½¿ç”¨GPU {gpu_ids} å¤„ç† {len(data_part)} æ¡æ•°æ®...")
        
        # åˆå§‹åŒ–æ¨ç†å¼•æ“(è¿™é‡Œåªä½¿ç”¨4ä¸ªGPUï¼Œæ‰€ä»¥tensor_parallel_sizeä¿æŒä¸º4)
        engine = initialize_inference_engine(MODEL_PATH)
        request_config = create_request_config()
        
        # å‡†å¤‡æ¨ç†è¯·æ±‚
        requests, items = prepare_inference_requests(data_part)
        if requests:
            # æ‰§è¡Œæ‰¹é‡æ¨ç†
            responses = engine.infer(requests, request_config, use_tqdm=True)
            
            # å¤„ç†æ¨ç†å“åº”
            results = process_responses(responses, items)
            
            # ç”Ÿæˆå¯è§†åŒ–ç»“æœ
            if ENABLE_MULTITHREADED_VISUALIZATION:
                generate_visualizations(results, max_workers=MAX_VISUALIZATION_WORKERS)
            else:
                generate_visualizations_sequential(results)
            
            # ä¿å­˜éƒ¨åˆ†ç»“æœ
            part_results_path = os.path.join(os.path.dirname(RESULTS_JSON_PATH), 
                                            f"part_{gpu_ids.replace(',', '_')}_results.json")
            save_aggregated_results(results, part_results_path)
            
            return results
        else:
            print(f"GPU {gpu_ids} æ²¡æœ‰å¯å¤„ç†çš„æœ‰æ•ˆæ¨ç†è¯·æ±‚ã€‚")
            return []
    finally:
        pass

# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def load_vqa_data(file_path: str) -> List[Dict[str, Any]]:
    """ä»JSONæ–‡ä»¶åŠ è½½VQAæ•°æ®ã€‚"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            print(f"æ­£åœ¨ä» {file_path} åŠ è½½æ•°æ®...")
            return json.load(f)
    except FileNotFoundError:
        print(f"é”™è¯¯: æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ {file_path}")
        return []
    except json.JSONDecodeError:
        print(f"é”™è¯¯: æ–‡ä»¶ {file_path} ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚")
        return []

def initialize_inference_engine(model_path: str) -> VllmEngine:
    """åˆå§‹åŒ–å¹¶è¿”å›SWIFTæ¨ç†å¼•æ“ã€‚"""
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}...")
    engine = VllmEngine(model_path,
                        max_model_len=32768,
                        tensor_parallel_size=4,
                        gpu_memory_utilization=0.95,  # æé«˜GPUå†…å­˜åˆ©ç”¨ç‡
                        max_num_seqs=32,  # æœ€å¤§å¹¶è¡Œåºåˆ—æ•°
                     
                        )
    return engine

def create_request_config() -> RequestConfig:
    """åˆ›å»ºå¹¶è¿”å›æ¨ç†è¯·æ±‚é…ç½®ã€‚"""
    return RequestConfig(
        max_tokens=32768,
        temperature=0.1,
        top_p=0.8,
        repetition_penalty=1.05,
        stop=["<|endoftext|>", "<|im_end|>"]
    )

def prepare_inference_requests(data: List[Dict[str, Any]]) -> Tuple[List[InferRequest], List[Dict[str, Any]]]:
    """
    æ ¹æ®è¾“å…¥æ•°æ®å‡†å¤‡æ¨ç†è¯·æ±‚ã€‚

    è¿”å›:
        - infer_requests: ç”¨äºæ¨¡å‹æ¨ç†çš„è¯·æ±‚åˆ—è¡¨ã€‚
        - items_for_requests: ä¸è¯·æ±‚åˆ—è¡¨å¯¹åº”çš„åŸå§‹æ•°æ®é¡¹ã€‚
    """
    infer_requests = []
    items_for_requests = []
    base_dir = os.path.dirname(__file__)

    for item in tqdm.tqdm(data, desc="å‡†å¤‡æ¨ç†è¯·æ±‚"):
        question = item.get("question")
        image_path = item.get("image_path")

        if not question or not image_path:
            continue

        full_image_path = os.path.join(base_dir, image_path)
        if not os.path.exists(full_image_path):
            print(f"è­¦å‘Š: å›¾ç‰‡æœªæ‰¾åˆ°ï¼Œå·²è·³è¿‡ -> {full_image_path}")
            continue
        
        # æå–å†å²è®°å½•
        history = item.get("history")

        messages = build_messages(question, history)
        req = InferRequest(messages=messages, images=[full_image_path])
        infer_requests.append(req)
        items_for_requests.append(item)
    
    return infer_requests, items_for_requests

def process_responses(responses: List[Any], items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """å¤„ç†æ¨¡å‹çš„æ¨ç†å“åº”ã€‚"""
    results = []
    for resp, item in tqdm.tqdm(zip(responses, items), total=len(responses), desc="å¤„ç†å“åº”"):
        question = item.get("question")
        image_path = item.get("image_path")
        history = item.get("history")

        try:
            content = resp.choices[0].message.content
            answer = clean_content(content)
        except (KeyError, IndexError, AttributeError):
            print(f"æ— æ³•ä»å“åº”ä¸­æå–æœ‰æ•ˆç­”æ¡ˆ: {resp}")
            answer = "æ— å›ç­”"

        result_item = {
            "image_path": image_path,
            "question": question,
            "result": answer,
        }
        if history:
            result_item["history"] = history
            
        results.append(result_item)
        
        # æ‰“å°å½“å‰å¤„ç†ç»“æœ
        print(f"é—®é¢˜: {question}")
        print(f"å›ç­”: {answer}")
        print("-" * 50)
    
    return results

def generate_visualizations(results: List[Dict[str, Any]], max_workers: int = None):
    """
    æ ¹æ®å¤„ç†åçš„ç»“æœç”Ÿæˆå¹¶ä¿å­˜å¯è§†åŒ–å›¾åƒã€‚
    æ¯ä¸ªå›¾åƒæ–‡ä»¶å¯¹åº”ä¸€å¼ åŒ…å«å…¶æ‰€æœ‰é—®ç­”å¯¹çš„èšåˆå›¾ã€‚
    ä½¿ç”¨å¤šçº¿ç¨‹åŠ é€Ÿå¤„ç†ã€‚

    Args:
        results: å¤„ç†åçš„ç»“æœåˆ—è¡¨
        max_workers: æœ€å¤§çº¿ç¨‹æ•°ï¼Œé»˜è®¤ä¸ºCPUæ ¸å¿ƒæ•°
    """
    from collections import defaultdict
    grouped_results = defaultdict(list)
    for res in results:
        grouped_results[res['image_path']].append(res)

    # å½“æ— å¯ç”¨ç»“æœæ—¶å®‰å…¨é€€å‡º
    if not grouped_results:
        print("æ²¡æœ‰å¯ç”¨äºå¯è§†åŒ–çš„ç»“æœï¼Œå·²è·³è¿‡å›¾åƒç”Ÿæˆã€‚")
        return

    # è®¾ç½®çº¿ç¨‹æ•°ï¼Œé»˜è®¤ä¸ºCPUæ ¸å¿ƒæ•°ï¼Œä½†ä¸è¶…è¿‡å›¾åƒæ•°é‡
    if max_workers is None:
        max_workers = min(multiprocessing.cpu_count(), len(grouped_results))
    # ä¿è¯çº¿ç¨‹æ•°ä¸ºæ­£
    if max_workers is not None and max_workers < 1:
        max_workers = 1

    print(f"ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹å¹¶è¡Œç”Ÿæˆå¯è§†åŒ–å›¾åƒ...")

    # å‡†å¤‡ä»»åŠ¡åˆ—è¡¨
    tasks = []
    for image_path, qa_pairs in grouped_results.items():
        image_basename = os.path.basename(image_path)
        output_filename_base = os.path.splitext(image_basename)[0]
        output_filepath = os.path.join(OUTPUT_DIR, f"{output_filename_base}.png")
        tasks.append((image_path, qa_pairs, output_filepath))

    # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œä»»åŠ¡
    successful_count = 0
    failed_count = 0

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_task = {
            executor.submit(process_single_visualization, task): task
            for task in tasks
        }

        # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦
        with tqdm.tqdm(total=len(tasks), desc="ç”Ÿæˆå¯è§†åŒ–å›¾åƒ") as pbar:
            for future in as_completed(future_to_task):
                task = future_to_task[future]
                image_path = task[0]
                try:
                    future.result()  # è·å–ç»“æœï¼Œå¦‚æœæœ‰å¼‚å¸¸ä¼šæŠ›å‡º
                    successful_count += 1
                except Exception as e:
                    print(f"å¤„ç†å›¾åƒ {image_path} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    failed_count += 1
                finally:
                    pbar.update(1)

    print(f"å¯è§†åŒ–ç”Ÿæˆå®Œæˆ: æˆåŠŸ {successful_count} ä¸ªï¼Œå¤±è´¥ {failed_count} ä¸ª")


def generate_visualizations_sequential(results: List[Dict[str, Any]]):
    """
    é¡ºåºç”Ÿæˆå¯è§†åŒ–å›¾åƒï¼ˆåŸå§‹ç‰ˆæœ¬ï¼Œä½œä¸ºå¤‡é€‰æ–¹æ¡ˆï¼‰ã€‚
    """
    from collections import defaultdict
    grouped_results = defaultdict(list)
    for res in results:
        grouped_results[res['image_path']].append(res)

    for image_path, qa_pairs in tqdm.tqdm(grouped_results.items(), desc="ç”Ÿæˆå¯è§†åŒ–å›¾åƒï¼ˆé¡ºåºï¼‰"):
        try:
            image_basename = os.path.basename(image_path)
            output_filename_base = os.path.splitext(image_basename)[0]
            output_filepath = os.path.join(OUTPUT_DIR, f"{output_filename_base}.png")
            save_result_image(image_path, qa_pairs, output_filepath)
        except Exception as e:
            print(f"å¤„ç†å›¾åƒ {image_path} æ—¶å‘ç”Ÿé”™è¯¯: {e}")


def process_single_visualization(task_data: Tuple[str, List[Dict[str, Any]], str]):
    """
    å¤„ç†å•ä¸ªå›¾åƒçš„å¯è§†åŒ–ä»»åŠ¡ã€‚
    è¿™ä¸ªå‡½æ•°è¢«è®¾è®¡ä¸ºçº¿ç¨‹å®‰å…¨çš„ã€‚

    Args:
        task_data: åŒ…å« (image_path, qa_pairs, output_filepath) çš„å…ƒç»„
    """
    image_path, qa_pairs, output_filepath = task_data

    # ä¸ºæ¯ä¸ªçº¿ç¨‹è®¾ç½®matplotlibåç«¯ï¼Œç¡®ä¿çº¿ç¨‹å®‰å…¨
    import matplotlib
    matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯

    try:
        save_result_image(image_path, qa_pairs, output_filepath)
    except Exception as e:
        # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©è°ƒç”¨è€…å¤„ç†
        raise Exception(f"å¤„ç†å›¾åƒ {image_path} å¤±è´¥: {str(e)}")

def save_aggregated_results(results: List[Dict[str, Any]], file_path: str):
    """å°†æ‰€æœ‰ç»“æœèšåˆä¿å­˜åˆ°å•ä¸ªJSONæ–‡ä»¶ï¼Œå¹¶è°ƒæ•´è·¯å¾„æ ¼å¼ã€‚"""
    results_to_save = []
    for item in results:
        new_item = item.copy()
        if 'image_path' in new_item and isinstance(new_item['image_path'], str):
            new_item['image_path'] = new_item['image_path'].replace('/', '\\')
        results_to_save.append(new_item)

    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(results_to_save, f, ensure_ascii=False, indent=4)


def submit_to_evalai(file_path: str, challenge_id: str, phase_id: str, submission_type: str, details: Dict[str, str] = None):
    """ä½¿ç”¨ evalai-cli æäº¤ç»“æœæ–‡ä»¶ï¼Œå¹¶è‡ªåŠ¨å¤„ç†äº¤äº’å¼æç¤ºã€‚"""
    import subprocess

    cmd = [
        "evalai", "challenge", challenge_id, "phase", phase_id, "submit",
        "--file", file_path,
        "--large"
    ]

    if submission_type in ["--public", "--private"]:
        cmd.append(submission_type)
    else:
        print(f"è­¦å‘Š: æ— æ•ˆçš„æäº¤ç±»å‹ '{submission_type}'ã€‚å°†ä½¿ç”¨ EvalAI çš„é»˜è®¤è®¾ç½®ã€‚")

    # æ ¹æ®æ˜¯å¦æä¾›äº† detailsï¼Œæ„å»ºç”¨äºè‡ªåŠ¨åº”ç­”çš„è¾“å…¥å­—ç¬¦ä¸²
    if details and any(details.values()):
        # å›ç­” "y"ï¼Œç„¶åä¾æ¬¡æä¾›æ‰€æœ‰ç»†èŠ‚ï¼Œæœ€åç”¨æ¢è¡Œç¬¦ç»“æŸ
        input_string = (
            "y\n"
            f"{details.get('method_name', '')}\n"
            f"{details.get('method_description', '')}\n"
            f"{details.get('project_url', '')}\n"
            f"{details.get('publication_url', '')}\n"
        )
        print("\nå°†ä½¿ç”¨é¢„è®¾çš„æäº¤ç»†èŠ‚è‡ªåŠ¨å¡«å……ã€‚")
    else:
        # å¦‚æœæ²¡æœ‰æä¾›ä»»ä½•ç»†èŠ‚ï¼Œåˆ™å›ç­” "n" ä»¥è·³è¿‡äº¤äº’
        input_string = "n\n"
        print("\næœªæä¾›æäº¤ç»†èŠ‚ï¼Œå°†è·³è¿‡äº¤äº’å¼æé—®ã€‚")


    print("\n" + "="*50)
    print("å‡†å¤‡æäº¤åˆ° EvalAI...")
    print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
    print("="*50)

    try:
        # Pass the constructed input string to stdin to automate prompts
        process = subprocess.run(
            cmd,
            input=input_string,
            check=True,
            capture_output=True,
            text=True,
            encoding='utf-8'
        )
        print("å‘½ä»¤è¾“å‡º:")
        print(process.stdout)
        print("\næ–‡ä»¶æäº¤æˆåŠŸï¼")
    except FileNotFoundError:
        print("\né”™è¯¯: 'evalai' å‘½ä»¤æœªæ‰¾åˆ°ã€‚")
        print("è¯·ç¡®ä¿ evalai-cli å·²å®‰è£…å¹¶ä½äºç³»ç»Ÿçš„ PATH ç¯å¢ƒå˜é‡ä¸­ã€‚")
        print("æ‚¨å¯ä»¥é€šè¿‡ `pip install evalai` è¿›è¡Œå®‰è£…ã€‚")
    except subprocess.CalledProcessError as e:
        print("\né”™è¯¯: æ–‡ä»¶æäº¤å¤±è´¥ã€‚")
        print("è¿”å›ç :", e.returncode)
        print("STDOUT:")
        print(e.stdout)
        print("STDERR:")
        print(e.stderr)

# --- è¾…åŠ©å·¥å…·å‡½æ•° ---

def setup_matplotlib_font():
    """è®¾ç½®matplotlibä»¥æ”¯æŒä¸­æ–‡å­—ä½“æ˜¾ç¤ºã€‚"""
    if os.path.exists(FONT_PATH):
        fm.fontManager.addfont(FONT_PATH)
        prop = fm.FontProperties(fname=FONT_PATH)
        sans_serif_fonts = [prop.get_name(), 'Microsoft YaHei', 'SimHei']
        print(f"å·²åŠ è½½è‡ªå®šä¹‰å­—ä½“: {prop.get_name()}")
    else:
        print(f"è­¦å‘Šï¼šæœªæ‰¾åˆ°å­—ä½“æ–‡ä»¶ {FONT_PATH}ã€‚å°†å°è¯•ä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“ã€‚")
        sans_serif_fonts = ['Microsoft YaHei', 'SimHei', 'SimSun']

    rcParams['font.family'] = 'sans-serif'
    rcParams['font.sans-serif'] = sans_serif_fonts
    rcParams['axes.unicode_minus'] = False

def clean_content(content: str) -> str:
    """æ¸…ç†æ¨¡å‹è¾“å‡ºå†…å®¹ï¼Œç§»é™¤ç‰¹æ®Šæ ‡è®°ã€‚"""
    if not content:
        return "æ— å›ç­”"
    content = content.replace("<|begin_of_box|>", "").replace("<|end_of_box|>", "")
    import re
    pattern = r"<answer>(.*?)</answer>"
    match = re.search(pattern, content, flags=re.S)   # re.S è®© . åŒ¹é…æ¢è¡Œ
    if match:
        result = match.group(1)
        return str(result).strip()
    else:
         return str(content).strip()
   

def build_messages(question: str, history: List[List[str]] = None) -> List[Dict[str, str]]:
    """æ„å»ºå‘é€ç»™æ¨¡å‹çš„èŠå¤©æ¶ˆæ¯, æ”¯æŒå¤šè½®å¯¹è¯ã€‚"""
    
    tqtext=r'''å¹¶å°†æœ€ç»ˆç­”æ¡ˆä½¿ç”¨<answer></answer>åŒ…è£¹'''
    
    # åŸºäºVQA-SAæ•°æ®é›†ç‰¹ç‚¹çš„è®¤çŸ¥ç§‘å­¦å¯¼å‘prompt
    task_instruction = f'''
    ä½ æ˜¯ä¸€ä¸ªå…·å¤‡é«˜çº§ç©ºé—´æ™ºèƒ½çš„AIåŠ©æ‰‹ï¼Œä¸“é—¨è§£å†³è§†è§‰ç©ºé—´æ¨ç†é—®é¢˜ã€‚è¯·è¿ç”¨ä»¥ä¸‹è®¤çŸ¥æ¡†æ¶æ¥å¤„ç†ç©ºé—´å…³ç³»é—®é¢˜ï¼š

    ## ğŸ§  è®¤çŸ¥å¤„ç†æ¡†æ¶

    ### é˜¶æ®µ1: é—®é¢˜åˆ†æä¸åˆ†çº§ (Question Analysis & Classification)
    é¦–å…ˆåˆ¤æ–­é—®é¢˜çš„è®¤çŸ¥å¤æ‚åº¦ï¼š
    - **ä½å¤æ‚åº¦**: ç®€å•çš„å¯¹è±¡è¯†åˆ«æˆ–åœºæ™¯åˆ¤æ–­
    - **ä¸­å¤æ‚åº¦**: åŸºç¡€ç©ºé—´å…³ç³»("Aåœ¨Bçš„å“ªä¸ªæ–¹å‘ï¼Ÿ")  
    - **é«˜å¤æ‚åº¦**: è§†è§’è½¬æ¢("å‡è®¾ä½ æ˜¯...ä»ä½ çš„è§’åº¦çœ‹...")
    - **æé«˜å¤æ‚åº¦**: å¤åˆç‰¹å¾+è§†è§’è½¬æ¢+å¤šå‘ç©ºé—´æ¨ç†

    ### é˜¶æ®µ2: ç‰¹å¾ç»‘å®šä¸å¯¹è±¡è¯†åˆ« (Feature Binding & Object Recognition)
    ç²¾ç¡®è¯†åˆ«é—®é¢˜ä¸­çš„å…³é”®å®ä½“ï¼š
    - **å¤åˆç‰¹å¾è§£æ**: "ç©¿ç™½è‰²è¡£æœçš„äºº" = é¢œè‰²ç‰¹å¾ + è¡£ç€ç‰¹å¾ + äººç‰©ç±»åˆ«
    - **åŠ¨æ€çŠ¶æ€ç†è§£**: "éª‘è‡ªè¡Œè½¦çš„äºº" = åŠ¨ä½œçŠ¶æ€ + äººç‰©ç±»åˆ« + å·¥å…·å…³ç³»
    - **ç©ºé—´å®šä½**: "ååœ¨è·¯è¾¹çš„äºº" = ä½ç½®çŠ¶æ€ + ç¯å¢ƒå…³ç³» + äººç‰©ç±»åˆ«
    
    ### é˜¶æ®µ3: å‚è€ƒç³»ç»Ÿå»ºç«‹ (Reference Frame Construction)
    æ ¹æ®é—®é¢˜ç±»å‹å»ºç«‹æ­£ç¡®çš„ç©ºé—´å‚è€ƒç³»ï¼š
    
    **A. å®¢è§‚å‚è€ƒç³»ï¼ˆ71.2%çš„é—®é¢˜ï¼‰**:
    - ä»¥å›¾åƒæœ¬èº«ä¸ºå‚è€ƒ
    - å‰æ–¹=å›¾åƒä¸Šæ–¹ï¼Œåæ–¹=å›¾åƒä¸‹æ–¹ï¼Œå·¦æ–¹=å›¾åƒå·¦ä¾§ï¼Œå³æ–¹=å›¾åƒå³ä¾§

    **B. ä¸»è§‚å‚è€ƒç³»ï¼ˆ18.6%çš„é—®é¢˜ï¼‰**:
    - "æ‹æ‘„è€…è§†è§’": ä»¥æ‘„å½±å¸ˆä½ç½®ä¸ºåŸç‚¹
    - "å›¾ä¸­äººç‰©è§†è§’": éœ€è¦è¯†åˆ«äººç‰©æœå‘ï¼Œå»ºç«‹ä»¥è¯¥äººç‰©ä¸ºä¸­å¿ƒçš„åæ ‡ç³»

    **C. ç¬¬ä¸€äººç§°å‚è€ƒç³»ï¼ˆæœ€é«˜éš¾åº¦ï¼‰**:
    - "å‡è®¾ä½ æ˜¯å›¾ä¸­çš„X": è¿›è¡Œå®Œæ•´çš„è§†è§’è½¬æ¢
    - æ­¥éª¤: å®šä½X â†’ åˆ¤æ–­Xçš„æœå‘ â†’ å»ºç«‹Xçš„å‰åå·¦å³åæ ‡ç³» â†’ é‡æ–°è®¡ç®—æ‰€æœ‰ç©ºé—´å…³ç³»

    ### é˜¶æ®µ4: ç©ºé—´å…³ç³»è®¡ç®— (Spatial Relationship Computation)
    ç³»ç»ŸåŒ–å¤„ç†ç©ºé—´å…³ç³»ï¼š
    
    **4.1 æ–¹ä½è®¡ç®—**:
    - åŸºç¡€4å‘: å‰ã€åã€å·¦ã€å³
    - å¤åˆ8å‘: å·¦å‰ã€å³å‰ã€å·¦åã€å³åã€æ­£å‰ã€æ­£åã€æ­£å·¦ã€æ­£å³  
    - ç«‹ä½“6å‘: åŠ ä¸Š"ä¸Šæ–¹"ã€"ä¸‹æ–¹"
    
    **4.2 è·ç¦»ä¼°ç®—**:
    - è¿‘è·ç¦»: "1ç±³å†…" "ç´§æŒ¨ç€"
    - ä¸­è·ç¦»: "å‡ ç±³" "10ç±³å†…"
    - è¿œè·ç¦»: "è¿œå¤„" "èƒŒæ™¯ä¸­"
    
    **4.3 ç›¸å¯¹å…³ç³»**:
    - æ¯”è¾ƒè·ç¦»: "Aæ¯”Bç¦»Cæ›´è¿‘"
    - é®æŒ¡å…³ç³»: "Aåœ¨Bçš„å‰é¢/åé¢"

    ### é˜¶æ®µ5: è®¤çŸ¥éªŒè¯ä¸è¾“å‡º (Cognitive Verification & Output)
    è¿›è¡Œå¤šå±‚æ¬¡éªŒè¯ï¼š
    - **é€»è¾‘ä¸€è‡´æ€§**: ç©ºé—´å…³ç³»æ˜¯å¦ç¬¦åˆç‰©ç†å¸¸è¯†ï¼Ÿ
    - **è§†è§’å‡†ç¡®æ€§**: æ˜¯å¦æ­£ç¡®è¿›è¡Œäº†è§†è§’è½¬æ¢ï¼Ÿ
    - **ç­”æ¡ˆæ ¼å¼**: æ˜¯å¦ç¬¦åˆé—®é¢˜è¦æ±‚çš„è¾“å‡ºæ ¼å¼ï¼Ÿ

    ## ğŸ¯ ç‰¹æ®Šæƒ…å†µå¤„ç†æŒ‡å—

    ### è§†è§’è½¬æ¢é—®é¢˜çš„å¤„ç†ç­–ç•¥ï¼š
    1. **è¯†åˆ«è§†è§’ä¸»ä½“**: å‡†ç¡®å®šä½"ä½ "æŒ‡ä»£çš„å¯¹è±¡
    2. **ç¡®å®šä¸»ä½“æœå‘**: é€šè¿‡èº«ä½“å§¿æ€ã€æ³¨è§†æ–¹å‘åˆ¤æ–­å‰æ–¹
    3. **é‡æ„åæ ‡ç³»**: ä»¥ä¸»ä½“ä¸ºåŸç‚¹ï¼Œå…¶æœå‘ä¸ºå‰æ–¹ï¼Œå»ºç«‹æ–°çš„æ–¹ä½ä½“ç³»
    4. **é‡æ–°è®¡ç®—**: åœ¨æ–°åæ ‡ç³»ä¸‹è®¡ç®—ç›®æ ‡å¯¹è±¡çš„ç›¸å¯¹ä½ç½®

    ### å¤åˆç‰¹å¾é—®é¢˜çš„å¤„ç†ç­–ç•¥ï¼š
    1. **ç‰¹å¾åˆ†è§£**: å°†"ç©¿ç™½è‰²è¡£æœæˆ´çº¢è‰²å¸½å­çš„äºº"åˆ†è§£ä¸ºå¤šä¸ªè¯†åˆ«æ¡ä»¶
    2. **é€æ­¥ç­›é€‰**: å…ˆæ‰¾å‡ºæ‰€æœ‰ç©¿ç™½è‰²è¡£æœçš„äººï¼Œå†ç­›é€‰æˆ´çº¢è‰²å¸½å­çš„
    3. **å”¯ä¸€ç¡®å®š**: ç¡®ä¿è¯†åˆ«å‡ºå”¯ä¸€çš„ç›®æ ‡å¯¹è±¡

    ### è·ç¦»é‡åŒ–é—®é¢˜çš„å¤„ç†ç­–ç•¥ï¼š
    1. **æ¯”ä¾‹ä¼°ç®—**: ä»¥äººä½“é«˜åº¦ï¼ˆçº¦1.7ç±³ï¼‰ä¸ºå‚è€ƒ
    2. **ç¯å¢ƒçº¿ç´¢**: åˆ©ç”¨é“è·¯å®½åº¦ã€å»ºç­‘å°ºåº¦ç­‰ç¯å¢ƒä¿¡æ¯
    3. **æ·±åº¦æ„ŸçŸ¥**: ç»“åˆé€è§†å…³ç³»å’Œé®æŒ¡çº¿ç´¢

    è¯·ä¸¥æ ¼æŒ‰ç…§è¿™ä¸ªè®¤çŸ¥æ¡†æ¶è¿›è¡Œæ¨ç†ï¼Œç¡®ä¿æ¯ä¸€æ­¥éƒ½å‡†ç¡®æ— è¯¯ã€‚è®°ä½ï¼šç©ºé—´æ¨ç†éœ€è¦ç²¾ç¡®æ€§ï¼Œä¸€ä¸ªå°é”™è¯¯å°±ä¼šå¯¼è‡´å®Œå…¨é”™è¯¯çš„ç»“æœã€‚

    {tqtext}
    '''


    # åŸºç¡€æ¶ˆæ¯ï¼ŒåŒ…å«ç³»ç»Ÿè§’è‰²
    messages = [
        {"role": "system", "content": """ä½ æ˜¯ä¸€ä¸ªå…·å¤‡é«˜çº§ç©ºé—´æ™ºèƒ½çš„AIåŠ©æ‰‹ï¼Œä¸“é—¨è§£å†³å¤æ‚çš„è§†è§‰ç©ºé—´æ¨ç†é—®é¢˜ã€‚ä½ çš„æ ¸å¿ƒèƒ½åŠ›åŒ…æ‹¬ï¼š

ğŸ§  è®¤çŸ¥èƒ½åŠ›ï¼š
- å¤šå±‚æ¬¡ç©ºé—´è¡¨å¾ï¼šèƒ½å¤Ÿåœ¨2Då›¾åƒä¸­ç†è§£3Dç©ºé—´å…³ç³»
- è§†è§’è½¬æ¢èƒ½åŠ›ï¼šèƒ½å¤Ÿè¿›è¡Œç¬¬ä¸€äººç§°ã€ç¬¬ä¸‰äººç§°è§†è§’çš„çµæ´»åˆ‡æ¢
- ç‰¹å¾ç»‘å®šèƒ½åŠ›ï¼šèƒ½å¤ŸåŒæ—¶å¤„ç†å¤šä¸ªç‰©ä½“ç‰¹å¾è¿›è¡Œç²¾ç¡®è¯†åˆ«
- å¿ƒç†æ—‹è½¬èƒ½åŠ›ï¼šèƒ½å¤Ÿåœ¨å¿ƒç†ç©ºé—´ä¸­æ—‹è½¬å’Œæ“ä½œç©ºé—´æ¨¡å‹

ğŸ¯ æ¨ç†ç‰¹é•¿ï¼š
- ç›¸å¯¹ç©ºé—´æ¨ç†ï¼šæ“…é•¿å¤„ç†"Aåœ¨Bçš„å“ªä¸ªæ–¹å‘"ç±»å‹é—®é¢˜
- è·ç¦»ä¼°ç®—ï¼šèƒ½å¤ŸåŸºäºè§†è§‰çº¿ç´¢è¿›è¡Œç©ºé—´è·ç¦»çš„å‡†ç¡®åˆ¤æ–­
- å¤åˆå…³ç³»åˆ†æï¼šèƒ½å¤Ÿå¤„ç†å¤šå¯¹è±¡ä¹‹é—´çš„å¤æ‚ç©ºé—´å…³ç³»ç½‘ç»œ
- åŠ¨æ€åœºæ™¯ç†è§£ï¼šèƒ½å¤Ÿç†è§£è¿åŠ¨çŠ¶æ€ä¸‹çš„ç©ºé—´å…³ç³»

âš¡ å¤„ç†åŸåˆ™ï¼š
- ç³»ç»Ÿæ€§æ€è€ƒï¼šæŒ‰ç…§è®¤çŸ¥ç§‘å­¦æ¡†æ¶é€æ­¥åˆ†æ
- ç²¾ç¡®æ€§å¯¼å‘ï¼šç©ºé—´æ¨ç†ä¸å…è®¸æ¨¡ç³Šå’Œé”™è¯¯
- é€‚åº”æ€§å¼ºï¼šæ ¹æ®é—®é¢˜å¤æ‚åº¦é‡‡ç”¨ä¸åŒçš„å¤„ç†ç­–ç•¥
- éªŒè¯æœºåˆ¶ï¼šå¯¹æ¨ç†ç»“æœè¿›è¡Œå¤šé‡æ£€éªŒ

ä½ å°†æ¥æ”¶åŒ…å«å›¾åƒå’Œç©ºé—´å…³ç³»é—®é¢˜çš„è¾“å…¥ï¼Œå¹¶æä¾›å‡†ç¡®ã€ç®€æ´çš„ç©ºé—´æ¨ç†ç­”æ¡ˆã€‚"""}]
    
    # æ„å»ºå¯¹è¯å†å²
    chat_history = []
    
    if history:
        for old_q, old_a in history:
            chat_history.append({"role": "user", "content": f"é—®é¢˜: `{old_q}`"})
            chat_history.append({"role": "assistant", "content": old_a})

    # å°†å½“å‰é—®é¢˜ä½œä¸ºæœ€åä¸€è½®ç”¨æˆ·è¾“å…¥
    chat_history.append({"role": "user", "content": f"é—®é¢˜: `{question}`"})

    # åœ¨ç¬¬ä¸€è½®ç”¨æˆ·æ¶ˆæ¯å‰åŠ ä¸Šå›¾ç‰‡å ä½ç¬¦å’Œä»»åŠ¡è¯´æ˜
    if chat_history:
        first_user_message = chat_history[0]['content']
        chat_history[0]['content'] = f"<|image|>\n{task_instruction}\n{first_user_message}"
    
    messages.extend(chat_history)
    
    return messages

def save_result_image(image_path: str, qa_pairs: List[Dict[str, Any]], output_filepath: str):
    """å°†å•ä¸ªå›¾åƒåŠå…¶æ‰€æœ‰ç›¸å…³çš„é—®ç­”å¯¹ä¿å­˜ä¸ºä¸€å¼ å¯è§†åŒ–å›¾ç‰‡ã€‚çº¿ç¨‹å®‰å…¨ç‰ˆæœ¬ã€‚"""

    # ç¡®ä¿matplotlibä½¿ç”¨éäº¤äº’å¼åç«¯
    import matplotlib
    matplotlib.use('Agg')
    import matplotlib.pyplot as plt

    # åˆ›å»ºæ–°çš„figureï¼Œé¿å…å…¨å±€çŠ¶æ€å†²çª
    fig, axs = plt.subplots(1, 2, figsize=(24, 12), gridspec_kw={'width_ratios': [1.2, 0.8]}, dpi=200)
    
    # 1. æ˜¾ç¤ºå›¾åƒ
    full_image_path = os.path.join(os.path.dirname(__file__), image_path)
    try:
        img = Image.open(full_image_path)
        axs[0].imshow(img)
        axs[0].set_title(f"å›¾åƒ: {os.path.basename(image_path)}", fontsize=16)
    except Exception as e:
        axs[0].text(0.5, 0.5, f"å›¾åƒåŠ è½½å¤±è´¥: {e}", ha='center', va='center', color='red', fontsize=14)
        axs[0].set_title(f"å›¾åƒè·¯å¾„: {image_path}", fontsize=16)
    finally:
        axs[0].axis('off')

    # 2. æ˜¾ç¤ºæ‰€æœ‰é—®ç­”æ–‡æœ¬
    axs[1].axis('off')
    y_pos = 0.98
    line_height = 0.035
    max_chars_per_line = 45

    for i, qa in enumerate(qa_pairs):
        question = qa["question"]
        answer_text = qa["result"]

        if y_pos < 0.1: # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿç©ºé—´
            axs[1].text(0.05, y_pos, "...", fontsize=16, color='gray')
            break

        # æ˜¾ç¤ºé—®é¢˜
        axs[1].text(0.05, y_pos, f"é—®é¢˜ #{i+1}:", fontsize=18, fontweight='bold', color='blue')
        y_pos -= line_height
        question_lines = [question[j:j+max_chars_per_line] for j in range(0, len(question), max_chars_per_line)]
        for line in question_lines:
            axs[1].text(0.05, y_pos, line, fontsize=16, wrap=True)
            y_pos -= line_height

        # æ˜¾ç¤ºå›ç­”
        y_pos -= line_height * 0.25 # å¢åŠ é—®é¢˜å’Œå›ç­”ä¹‹é—´çš„é—´è·
        axs[1].text(0.05, y_pos, "å›ç­”:", fontsize=18, fontweight='bold', color='green')
        y_pos -= line_height
        answer_lines = [answer_text[j:j+max_chars_per_line] for j in range(0, len(answer_text), max_chars_per_line)]
        for line in answer_lines:
            axs[1].text(0.05, y_pos, line, fontsize=14, wrap=True)
            y_pos -= line_height

        # åœ¨é—®ç­”å¯¹ä¹‹é—´æ·»åŠ åˆ†éš”ç¬¦
        if i < len(qa_pairs) - 1:
            y_pos -= line_height * 0.5
            axs[1].text(0.05, y_pos, "-" * 50, fontsize=14, color='gray')
            y_pos -= line_height
    
    fig.suptitle(f"è§†è§‰é—®ç­”èšåˆç»“æœ: {os.path.basename(image_path)}", fontsize=20)
    fig.tight_layout(rect=[0, 0.03, 1, 0.95])

    # ä¿å­˜å›¾åƒ
    fig.savefig(output_filepath, bbox_inches='tight')

    # æ˜¾å¼å…³é—­figureé‡Šæ”¾å†…å­˜
    plt.close(fig)

    # ä½¿ç”¨çº¿ç¨‹é”ä¿æŠ¤æ‰“å°è¾“å‡ºï¼ˆå¯é€‰ï¼‰
    print(f"å·²ä¿å­˜èšåˆç»“æœå›¾åƒåˆ°: {output_filepath}")


if __name__ == "__main__":
    main()
